---
title: "Analysis of sustainability disclosure of food retailers in Europe"
author: "Johannes W.H. van der Waal"
date: "7-3-2022"
output:   html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
library(quanteda)
library(tidyverse)
```

# Objective

- objectively chart the sustainability themes of food retailers
- identify relevant topics that we must not miss
- match our sustainability focus areas with those of retailers

# Method
```{r stats1, echo=FALSE, message = FALSE}

#load bulk data
load("mat_mr.Rdata")

library(readxl)
company_names <- read_excel("company_names.xlsx") 

#construct corpus
corp_mr <- quanteda::corpus(mat_mr)

#make corpus subset based on language
corp_en <- corpus_subset(corp_mr, language == "EN")
docvars <- docvars(corp_en)

# number of English reports
nrow(docvars)
```
- Text analysis of `r nrow(docvars)` sustainability reports.
- Non-English reports were converted to English language with Deepl.com
- Supervised and non-supervised thematic analysis 

```{r stats2, eval = TRUE, echo = FALSE}
# retrieve text stats by company
load("raw_stats.Rda")
clean_stats <- raw_stats %>% 
  mutate(company = substr(document, 12,19)) %>%
  left_join(.,company_names) 
```
## Description of the reports
```{r plot, eval=TRUE, echo = FALSE, message = FALSE}
library(ggthemes)
library(ggrepel)
#determine order og high to low sentence scores for ggplot
order <- clean_stats %>% 
  group_by(retailer) %>%
  summarize(zinnen = sum(sents), country= as.factor(country), retailer = as.factor(retailer)) %>% 
  unique() %>%
  group_by(country) %>%
  summarize(z = sum(zinnen)) %>%
  arrange(desc(z)) %>%
  pull(country)

p <- clean_stats %>% 
  group_by(retailer) %>%
  summarize(zinnen = sum(sents), country= as.factor(country), retailer = as.factor(retailer)) %>%
  unique() %>%
  ggplot(aes(reorder(country, -zinnen), zinnen, label = retailer, fill = retailer)) +
  geom_bar(stat = "identity") +
  geom_text(size = 3, position = position_stack(vjust = 0.5)) +
  ggtitle("Number of sentences in food retail sustainability reports per country") +
  xlab("country") + ylab("Number of sentences") +
  theme_economist() 
p + theme(legend.position="none") +
  scale_x_discrete(limits=order) #this puts the columns in the order of the highest to lowest
  coord_flip() 

```

`
You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
```{r lda, echo=FALSE}
library(quanteda)
library(readtext)
library(quanteda.textstats)
library(quanteda.corpora)
library(seededlda)
library(topicmodels)
library(stringr)
library(tidyverse)

#split in paragraphs
corp_mr_par <- corp_en %>%
  corpus_segment(pattern = "â€¢")
docvars(corp_mr_par) %>% group_by(company, year) %>% summarize()

#make a list of unique company designators
company_list <- unique(docvars(corp_en)) %>% select(company)
write_excel_csv(company_list, "companylist.txt")

#read company names
library(readxl)
company_names <- read_excel("company_names.xlsx") 
cl <- company_names$retailer %>% tokens() %>% tokens_split() %>% unlist()
words <- c("sek", "eur", "ica", "coop", "colruyt", "axfood", "ahold", "delhaize",
           "million", "appendix", "see", "axfood's", "gruppen's","co-op", "asda",
           "aldi", "per", "year", "also", "can", "use", "chf", "finland",
           "switzerland", "delhaize's", "years", "euro", "sweden", "kesko",
           "spain", "steghaus", "mbb", "italian", "thanks", "new", "u.s.",
           "transgourmet", "gmbh", "g.m.b.h.", "esselunga", "milan",
           "euro", "naturama", "della", "banco", "alimentar", "co-operative",
           "zurich", "basel", "bern", "franc", "billion", "italia",
           "april", "januari", "u.", "adriatico", "belgium", 
           "france", "swiss", "belgian", "virya","norgesgruppen",
           "baltic", "kesko")
cl <- append(cl, words)


#tokenize
toks_nostop <- corp_mr_par %>% 
  tokens(remove_punct = TRUE, remove_symbols = TRUE, 
         remove_numbers = TRUE, remove_url = TRUE) %>% 
  tokens_select(min_nchar = 3) %>%
  tokens_remove(stopwords("en")) %>%
  tokens_remove(pattern = cl) %>%
  tokens_remove(c("*-time", "*-timeUpdated", "GMT", "BST", "*.com", "ltd", "group", 
                  "holdings", "inc", "business"))  


# create document feature matrices
# base dfm 
dfm <- dfm(toks_nostop) %>%dfm_remove(pattern = cl)
dfm_stem <- dfm_wordstem(dfm)

# LDA
a2 <- Sys.time()
lda <- textmodel_lda(dfm_stem, k = 9, verbose = T, alpha = 1)
summary(lda)
df_lda <- as.data.frame(lda$theta) %>% 
  tibble::rownames_to_column(., "document")
b2 <- Sys.time()
t2 <- b2-a2
t2



# use LDAvis to explore topics
library(LDAvis)
library(servr)
json <- createJSON(phi = lda$phi,
                   theta = lda$theta, 
                   doc.length = quanteda::ntoken(dfm_stem),
                   vocab = quanteda::featnames(dfm_stem), 
                   term.frequency = quanteda::featfreq(dfm_stem))
serVis(json, out.dir = 'vis', 
       open.browser = T)
```
